@article{fang_hyperspherical_2021,
 abstract = {Network-based information has been widely explored and exploited in the information retrieval literature. Attributed networks, consisting of nodes, edges as well as attributes describing properties of nodes, are a basic type of network-based data, and are especially useful for many applications. Examples include user profiling in social networks and item recommendation in user-item purchase networks. Learning useful and expressive representations of entities in attributed networks can provide more effective building blocks to down-stream network-based tasks such as link prediction and attribute inference. Practically, input features of attributed networks are normalized as unit directional vectors. However, most network embedding techniques ignore the spherical nature of inputs and focus on learning representations in a Gaussian or Euclidean space, which, we hypothesize, might lead to less effective representations. To obtain more effective representations of attributed networks, we investigate the problem of mapping an attributed network with unit normalized directional features into a non-Gaussian and non-Euclidean space. Specifically, we propose a hyperspherical variational co-embedding for attributed networks (HCAN), which is based on generalized variational auto-encoders for heterogeneous data with multiple types of entities. HCAN jointly learns latent embeddings for both nodes and attributes in a unified hyperspherical space such that the affinities between nodes and attributes can be captured effectively. We argue that this is a crucial feature in many real-world applications of attributed networks. Previous Gaussian network embedding algorithms break the assumption of uninformative prior, which leads to unstable results and poor performance. In contrast, HCAN embeds nodes and attributes as von Mises-Fisher distributions, and allows one to capture the uncertainty of the inferred representations. Experimental results on eight datasets show that HCAN yields better performance in a number of applications compared with nine state-of-the-art baselines.},
 author = {Fang, Jinyuan and Liang, Shangsong and Meng, Zaiqiao and De Rijke, Maarten},
 doi = {10.1145/3478284},
 file = {Full Text PDF:files/3667/Fang et al. - 2021 - Hyperspherical Variational Co-embedding for Attrib.pdf:application/pdf},
 issn = {1046-8188},
 journal = {ACM Transactions on Information Systems},
 keywords = {generalized variational auto-encoders, hyperspherical representation, Network embedding},
 month = {December},
 number = {3},
 pages = {58:1--58:36},
 title = {Hyperspherical Variational Co-embedding for Attributed Networks},
 url = {https://dl.acm.org/doi/10.1145/3478284},
 urldate = {2023-11-11},
 volume = {40},
 year = {2021}
}
